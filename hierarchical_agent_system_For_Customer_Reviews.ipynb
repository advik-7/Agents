{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdkFPZSek91VMCQdTQRkid",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/advik-7/Agents/blob/main/hierarchical_agent_system_For_Customer_Reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MSx4Z7zdZsVJ",
        "outputId": "1992abed-7048-47a6-b0cc-5354454ede21"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.7->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.7->langchain_community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.17->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain_community) (2.23.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.2.2)\n",
            "Downloading langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: SQLAlchemy, python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "Successfully installed SQLAlchemy-2.0.35 dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.7 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9GXjv4urYtid"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "from transformers import pipeline\n",
        "from langchain.agents import initialize_agent, Tool, AgentType\n",
        "from langchain.chat_models import ChatOpenAI\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@tool\n",
        "def analyze_sentiment(feedback: str) -> str:\n",
        "    \"\"\"\n",
        "    Analyzes the sentiment of customer feedback using a Hugging Face model.\n",
        "    \"\"\"\n",
        "    sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "    sentiment = sentiment_pipeline(feedback)[0]\n",
        "    return f\"Sentiment: {sentiment['label']}, Confidence: {sentiment['score']:.2f}\"\n",
        "\n",
        "@tool\n",
        "def extract_topics(feedback: str) -> str:\n",
        "    \"\"\"\n",
        "    Extracts topics from customer feedback using zero-shot classification.\n",
        "    \"\"\"\n",
        "    topic_pipeline = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "    candidate_labels = [\"price\", \"quality\", \"customer service\", \"delivery\", \"return policy\"]\n",
        "    topics = topic_pipeline(feedback, candidate_labels=candidate_labels)\n",
        "    top_topic = topics[\"labels\"][0]\n",
        "    confidence = topics[\"scores\"][0]\n",
        "    return f\"Top Topic: {top_topic}, Confidence: {confidence:.2f}\"\n",
        "\n",
        "@tool\n",
        "def summarize_feedback(feedback: str) -> str:\n",
        "    \"\"\"\n",
        "    Summarizes customer feedback using a Hugging Face summarization model.\n",
        "    \"\"\"\n",
        "    summarization_pipeline = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "    summary = summarization_pipeline(feedback, max_length=50, min_length=20, do_sample=False)\n",
        "    return summary[0]['summary_text']\n"
      ],
      "metadata": {
        "id": "mXZtCvcyYuSY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SubAgent:\n",
        "    def __init__(self, name, tool):\n",
        "        self.name = name\n",
        "        self.tool = tool\n",
        "\n",
        "    def execute_task(self, input_text: str):\n",
        "        print(f\"{self.name} is processing the input...\")\n",
        "        result = self.tool(input_text)\n",
        "        print(f\"{self.name} result: {result}\")\n",
        "        return result\n"
      ],
      "metadata": {
        "id": "9wHsk8ygZ2zG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MainAgent:\n",
        "    def __init__(self, sentiment_tool, topic_tool, summarization_tool):\n",
        "        self.sentiment_agent = SubAgent(\"Sentiment Analysis Agent\", sentiment_tool)\n",
        "        self.topic_agent = SubAgent(\"Topic Extraction Agent\", topic_tool)\n",
        "        self.summarization_agent = SubAgent(\"Summarization Agent\", summarization_tool)\n",
        "\n",
        "    def distribute_tasks(self, feedback):\n",
        "        print(\"\\nMain Agent is distributing tasks...\\n\")\n",
        "\n",
        "        sentiment_result = self.sentiment_agent.execute_task(feedback)\n",
        "\n",
        "        topic_result = self.topic_agent.execute_task(feedback)\n",
        "\n",
        "        summary_result = self.summarization_agent.execute_task(feedback)\n",
        "\n",
        "        print(\"\\n--- Final Results ---\")\n",
        "        print(f\"Sentiment: {sentiment_result}\")\n",
        "        print(f\"Key Topics: {topic_result}\")\n",
        "        print(f\"Summary: {summary_result}\")\n",
        "\n",
        "        return {\n",
        "            \"sentiment\": sentiment_result,\n",
        "            \"topics\": topic_result,\n",
        "            \"summary\": summary_result,\n",
        "        }\n"
      ],
      "metadata": {
        "id": "3cECkFNYZ7Hp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    sentiment_tool = analyze_sentiment\n",
        "    topic_tool = extract_topics\n",
        "    summarization_tool = summarize_feedback\n",
        "\n",
        "    main_agent = MainAgent(sentiment_tool, topic_tool, summarization_tool)\n",
        "\n",
        "    print(\"Customer Feedback Analysis\\n\")\n",
        "    print(\"Please enter the customer feedback text below:\")\n",
        "    feedback_text = input(\"> \")\n",
        "    print(\"\\nProcessing feedback...\")\n",
        "    results = main_agent.distribute_tasks(feedback_text)\n",
        "\n",
        "    print(\"\\n--- Summary of Results ---\")\n",
        "    for task, result in results.items():\n",
        "        print(f\"{task.capitalize()}: {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaxBw0kkZ-oz",
        "outputId": "87fe8ce8-adfb-43ba-9243-a1fcecdaa812"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customer Feedback Analysis\n",
            "\n",
            "Please enter the customer feedback text below:\n",
            ">  The shoes are amazing but only issue I was unable to remove stains for the shoes\n",
            "\n",
            "Processing feedback...\n",
            "\n",
            "Main Agent is distributing tasks...\n",
            "\n",
            "Sentiment Analysis Agent is processing the input...\n",
            "Sentiment Analysis Agent result: Sentiment: NEGATIVE, Confidence: 0.89\n",
            "Topic Extraction Agent is processing the input...\n",
            "Topic Extraction Agent result: Top Topic: quality, Confidence: 0.96\n",
            "Summarization Agent is processing the input...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 50, but your input_length is only 19. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarization Agent result: The shoes are amazing but only issue I was unable to remove stains for the shoes.\n",
            "\n",
            "--- Final Results ---\n",
            "Sentiment: Sentiment: NEGATIVE, Confidence: 0.89\n",
            "Key Topics: Top Topic: quality, Confidence: 0.96\n",
            "Summary: The shoes are amazing but only issue I was unable to remove stains for the shoes.\n",
            "\n",
            "--- Summary of Results ---\n",
            "Sentiment: Sentiment: NEGATIVE, Confidence: 0.89\n",
            "Topics: Top Topic: quality, Confidence: 0.96\n",
            "Summary: The shoes are amazing but only issue I was unable to remove stains for the shoes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ny1rKsxmaBXW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}